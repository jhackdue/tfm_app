{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78740f79-8531-4a62-9f4f-5adef89bc748",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Trabajo de Fin de Máster: Applicación Web sobre un modelo de Question Answering en español"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb9343f-95f0-4c6f-b65e-b16568e25296",
   "metadata": {},
   "source": [
    "Este notebook recreará desde cero cómo realizar un **Fine-Tuning** de un modelo BERT para realizar un sistema de **Question Answering**.\n",
    "\n",
    "A partir del código creado en [repositorio](https://github.com/jhackdue/tfm_app), importaremos las librerías necesarias y empezaremos a pasar por fases de configuración, preprocesado, elección de parámetros, creación del modelo, entrenamiento y validación, predicción.\n",
    "\n",
    "\n",
    "Pero exactamente, ¿Cómo haremos que se entrene el modelo a partir de Bert?. Primero, miramos la estructura del modelo ajustado ya para este propósito de Question Answering:\n",
    "\n",
    "<img src=\"bert.png\" width=400 height=400 style=\"margin-left:auto; margin-right:auto\"/>\n",
    "\n",
    "En la memoria del TFM encontramos más detalle sobre esto, pero en resumidas cuentas:\n",
    "- Configuraremos los textos de preguntas y contextos en una sola secuencia tokenizada\n",
    "- Crearemos una red neuronal de dos neuronas que nos dirán dónde empiezan y acaba una respuesta dentro de los tokens del contexto.\n",
    "\n",
    "La salida de Bert de cada token (Ti) multiplicado por el peso de la primera neurona (S) nos da la probabilidad de que ese token sea el inicio de la respuesta. Pasa lo mismo si multiplicamos por el peso de la segunda neurona (E), obtenemos la probabilidad de que otro token (Tj) sea el final de la respuesta. La puntuación de un intervalo candidato sería $S . Ti + E . Tj$, el modelo que entrenamos intenta maximizar esta puntuación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cf5ac9-e830-4fb6-8fd4-54a7a4c9eb86",
   "metadata": {},
   "source": [
    "---\n",
    "## Índice General\n",
    "\n",
    "* [Capítulo 0: Configuración Inicial](#cap0)\n",
    "\n",
    "    * [Importación de librerías](#cap0.1)\n",
    "    * [Configuración del proyecto](#cap0.2)\n",
    "    * [visualización de datos](#cap0.3)\n",
    "\n",
    "* [Capítulo 1: Preprocesado de datos](#cap1)\n",
    "\n",
    "    * [Configurando el tokenizador](#cap1.1)\n",
    "    * [Modificando la configuración](#cap1.2)\n",
    "    * [Preprocesamiento](#cap1.3)\n",
    "    \n",
    "* [Capítulo 2: Construcción del modelo](#cap2)\n",
    "\n",
    "    * [Hiperparámetros](#cap2.1)\n",
    "    * [Callbacks](#cap2.2)\n",
    "    * [Formato Keras](#cap2.3)\n",
    "    * [Modelo](#cap2.4)\n",
    "    \n",
    "* [Capítulo 3: Entrenamiento y validación](#cap3)\n",
    "\n",
    "    * [Monitorización en Tensorboard](#cap3.1)\n",
    "    * [Entrenamiento](#cap3.2)\n",
    "    \n",
    "* [Capítulo 4: Predicción](#cap4)\n",
    "\n",
    "    * [Carga de modelo](#cap4.1)\n",
    "    * [Dato a evaluar](#cap4.2)\n",
    "    * [Modelo entrenado](#cap4.3)\n",
    "    * [Modelo remoto](#cap4.4)\n",
    "    * [Pipeline](#cap4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0491ae97-b49a-4573-875a-2afbebde416e",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "<a class=\"anchor\" id=\"cap0\"></a>\n",
    "## Capítulo 0: Configuración Inicial\n",
    "\n",
    "En esta parte del notebook empezaremos importando las librerías necesarias, posteriormente nos aseguraremos que las carpetas y ficheros creados etén en sus respectivos lugares y visualizaremos algunos ejemplos del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a49645-baf1-476f-acad-c81ef296efef",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"cap0.1\"></a>\n",
    "### Importación de librerias \n",
    "\n",
    "- Importamos librerías como numpy y json para el posterior tratado de los datos\n",
    "- Añadimos al entorno del notebook rutas fuera del directorio padre de este notebook\n",
    "- Importamos las librerías necesarias para realizar la lectura, preprocesado, entrenamiento y predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1e894d3-5ef1-4858-a1b4-c5264f985531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "ABS_DIR = os.path.join(os.getcwd(), \"..\")\n",
    "sys.path.append(ABS_DIR)\n",
    "\n",
    "\n",
    "import utils.read_and_write as rw\n",
    "import utils.preprocesado as pp\n",
    "import train.train_utils as tu\n",
    "import predict.predict_utils as pu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e790999e-916c-4202-babf-1485458b6cae",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"cap0.2\"></a>\n",
    "### Configuración del proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386460b8-8ebe-470e-9da5-047575c44c10",
   "metadata": {},
   "source": [
    "* Descargamos los ficheros de entrenamiento y evalución de SQuAD en español desde [aquí](https://github.com/ccasimiro88/TranslateAlignRetrieve)\n",
    "* Descargamos los ficheros de vocab y config con los que se entrenó BETO (Spanish BERT) desde [aquí](https://github.com/dccuchile/beto)\n",
    "* Con las funciones de rw, comprobamos que existen los ficheros descargados en los directorios indicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "241422d1-9ed0-4e17-8221-d798752988eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 16:15:05,605 tfm-app.log INFO: El fichero log tfm-app.log ha sido creado\n",
      "2021-11-09 16:15:05,624 tfm-app.log INFO: El fichero train-v2.0-es.json existe en D:\\tfm_app\\src\\project\\notebooks\\..\\data\\datasets\n",
      "2021-11-09 16:15:05,625 tfm-app.log INFO: El fichero dev-v2.0-es.json existe en D:\\tfm_app\\src\\project\\notebooks\\..\\data\\datasets\n",
      "2021-11-09 16:15:05,626 tfm-app.log INFO: El fichero vocab.txt existe en D:\\tfm_app\\src\\project\\notebooks\\..\\data\\models\n",
      "2021-11-09 16:15:05,628 tfm-app.log INFO: El fichero config.json existe en D:\\tfm_app\\src\\project\\notebooks\\..\\data\\models\n"
     ]
    }
   ],
   "source": [
    "CONFIG_DIR = os.path.join(ABS_DIR, \"config\\\\\")\n",
    "\n",
    "DATA_DIR = os.path.join(ABS_DIR, \"data\\\\\")\n",
    "LOG_DIR = os.path.join(DATA_DIR, \"logs\\\\\")\n",
    "MODELS_DIR = os.path.join(DATA_DIR, \"models\\\\\")\n",
    "DATASETS_DIR = os.path.join(DATA_DIR, \"datasets\\\\\")\n",
    "CHECKPOINTS_CALLBACK_DIR = os.path.join(DATA_DIR, \"checkpoints\\\\\")\n",
    "CACHE_DIR = os.path.join(DATA_DIR, \"cache\\\\\")\n",
    "\n",
    "logger = rw.crear_logger(\"tfm-app.log\")\n",
    "\n",
    "train_path = rw.comprobar_fichero_existe(os.path.join(DATASETS_DIR, \"train-v2.0-es.json\"), logger)\n",
    "eval_path = rw.comprobar_fichero_existe(os.path.join(DATASETS_DIR, \"dev-v2.0-es.json\"), logger)\n",
    "\n",
    "vocab_BERT_path = rw.comprobar_fichero_existe(os.path.join(MODELS_DIR, \"vocab.txt\"), logger)\n",
    "config_BERT_path = rw.comprobar_fichero_existe(os.path.join(MODELS_DIR, \"config.json\"), logger)\n",
    "\n",
    "config_file = rw.cargar_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3f3e5b-eee6-4f8b-9e28-91085be66a7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"cap0.3\"></a>\n",
    "### Visualización de datos \n",
    "\n",
    "Podemos comprobar, a partir de los ficheros json, cómo son los datos tanto de entrenamiento como de validación. Para ello primero los pasaremos a un Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a5a104c-b2a3-4a0e-b0c9-395b78c6c90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86818, 6)\n",
      "(9905, 6)\n"
     ]
    }
   ],
   "source": [
    "train_df = rw.json_to_dataframe(train_path)\n",
    "print(train_df.shape)\n",
    "eval_df = rw.json_to_dataframe(eval_path)\n",
    "print(eval_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7877eed1-42f1-46c8-93bf-d6e5c40168db",
   "metadata": {},
   "source": [
    "* Ejemplo de datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf9734de-84c1-41b4-bd14-52b5fb997560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título:\n",
      " Budismo\n",
      "------------------------------------------------------------------------------------------\n",
      "Párrafo:\n",
      " La segunda verdad es que el origen de la dukkha puede ser conocido. En el contexto de las cuatro verdades nobles, el origen de dukkha se explica comúnmente como deseo (Pali: Tanha) condicionado por la ignorancia (Pali: Avijja). En un nivel más profundo, la causa raíz del dukkha se identifica como ignorancia (Pali: Avijja) de la verdadera naturaleza de las cosas. La tercera verdad noble es que el cese completo de la dukkha es posible, y la cuarta verdad noble identifica un camino a este cese. [Nota 7]\n",
      "------------------------------------------------------------------------------------------\n",
      "Pregunta:\n",
      " El origen del dukkha se explica como deseo condicionado por qué?\n",
      "------------------------------------------------------------------------------------------\n",
      "Posicion de respuesta:\n",
      " 201\n",
      "------------------------------------------------------------------------------------------\n",
      "Respuesta:\n",
      " ignorancia\n"
     ]
    }
   ],
   "source": [
    "id_row = 5000\n",
    "print(f\"Título:\\n {train_df.iloc[id_row, 1]}\")\n",
    "print(\"---\"*30)\n",
    "print(f\"Párrafo:\\n {train_df.iloc[id_row, 2]}\")\n",
    "print(\"---\"*30)\n",
    "print(f\"Pregunta:\\n {train_df.iloc[id_row, 3]}\")\n",
    "print(\"---\"*30)\n",
    "print(f\"Posicion de respuesta:\\n {train_df.iloc[id_row, 4]}\")\n",
    "print(\"---\"*30)\n",
    "print(f\"Respuesta:\\n {train_df.iloc[id_row, 5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d352c444-4122-4fed-8f37-ef3b35b9d7ee",
   "metadata": {},
   "source": [
    "* Ejemplo de datos de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1807e35-592e-4e49-9029-dcd398efab5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título:\n",
      " Escuela privada\n",
      "------------------------------------------------------------------------------------------\n",
      "Párrafo:\n",
      " Las escuelas religiosas afiliadas y denominacionales forman una subcategoría de escuelas privadas. Algunas de estas escuelas enseñan educación religiosa, junto con los sujetos académicos habituales para impresionar las creencias y tradiciones de su fe particular en los estudiantes que asisten. Otros usan la denominación como una etiqueta más general para describir lo que los fundadores basaron en su creencia, manteniendo una fina distinción entre académicos y religión. Incluyen escuelas parroquiales, un término que a menudo se utiliza para denotar escuelas católicas romanas. Otros grupos religiosos representados en el sector de la educación privada K-12 incluyen protestantes, judíos, musulmanes y cristianos ortodoxos.\n",
      "------------------------------------------------------------------------------------------\n",
      "Pregunta:\n",
      " Junto con musulmanes, judíos y cristianos protestantes, ¿qué grupo religioso opera en particular escuelas privadas?\n",
      "------------------------------------------------------------------------------------------\n",
      "Posicion de respuesta:\n",
      " 563\n",
      "------------------------------------------------------------------------------------------\n",
      "Respuesta:\n",
      " católica\n"
     ]
    }
   ],
   "source": [
    "id_row = 5000\n",
    "print(f\"Título:\\n {eval_df.iloc[id_row, 1]}\")\n",
    "print(\"---\"*30)\n",
    "print(f\"Párrafo:\\n {eval_df.iloc[id_row, 2]}\")\n",
    "print(\"---\"*30)\n",
    "print(f\"Pregunta:\\n {eval_df.iloc[id_row, 3]}\")\n",
    "print(\"---\"*30)\n",
    "print(f\"Posicion de respuesta:\\n {eval_df.iloc[id_row, 4]}\")\n",
    "print(\"---\"*30)\n",
    "print(f\"Respuesta:\\n {eval_df.iloc[id_row, 5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc633059-e92b-442a-9edb-fab1cfc65475",
   "metadata": {},
   "source": [
    "---\n",
    "<a class=\"anchor\" id=\"cap1\"></a>\n",
    "## Capítulo 1: Preprocesado de datos\n",
    "\n",
    "En este capítulo obtendremos los datos que entrarán directamente en el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24a0e7-4512-4877-92b6-337523accfdf",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"cap1.1\"></a>\n",
    "### Configurando el tokenizador\n",
    "\n",
    "El tokenizador que se va a utilizar se creará a partir del vocabulario de tokens que tenemos en el directorio del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1693d3cf-9530-4a00-a758-637f57af595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizador = pp.obtener_tokenizador(vocab=vocab_BERT_path, lowercase=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a571c5b-4e6a-40a1-bb72-e8937dbfa13c",
   "metadata": {},
   "source": [
    "Por ejemplo, podemos tokenizar la siguiente frase y ver qué tokens asigna nuestro tokenizador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "438d5d85-95ad-41c1-a840-e9e72d8298e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids: [4, 2098, 1058, 1108, 3889, 1110, 1292, 2078, 1062, 3, 5]\n",
      "tokens: ['[CLS]', 'Esto', 'es', 'una', 'prueba', 'para', 'ver', 'cómo', 'se', '[UNK]', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizador.encode(\"Esto es una prueba para ver cómo se tokeniza\")\n",
    "print(f'ids: {tokens.ids}')\n",
    "print(f'tokens: {tokens.tokens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b01ebf-6375-477d-b13d-33ab1c2669bf",
   "metadata": {},
   "source": [
    "Vemos que cuenta con casi todos los tokens, excepto por la palabra \"tokenizar\" que no lo tenía en el vocabulario y pasa a ser el token [UNK]. También observamos que añade tanto al principio como al final, dos tokens [CLS] y [SEP]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8936e775-7c28-4e07-baa8-de861014814c",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cap1.2\"></a>\n",
    "### Modificando la configuración\n",
    "\n",
    "Tenemos la configuración de la aplicación para entrenar que cuenta con:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e76d7b1-8394-43e5-864e-6a6c95e3a8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logs': {'level': 'DEBUG',\n",
       "  'format': '%(asctime)s %(name)s %(levelname)s: %(message)s'},\n",
       " 'train': {'preprocess': {'max_seq_len': 384,\n",
       "   'lr': 0.05,\n",
       "   'batch_size': 64,\n",
       "   'nb_epoch': 20}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5bbe68-1d4e-42c9-9c7f-7051d8f571ec",
   "metadata": {},
   "source": [
    "Lo que haremos será añadir la parte del preprocesado a la configuración de Bert que tenemos en el directorio del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b17e121-5de7-47e1-8e3c-4bdd51ec9dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_BERT_path, 'r') as json_file:\n",
    "    config_BERT = json.load(json_file)\n",
    "config_BERT.update(config_file[\"train\"][\"preprocess\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b9eec0-e814-4cb3-9acb-ae8296736262",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cap1.3\"></a>\n",
    "### Preprocesamiento\n",
    "\n",
    "En esta parte del notebook, lo que vamos a hacer es, dado los datos de entrenamiento y validación en un DataFrame de pandas, convertirlos en un formato de tensorflow. En particular obtendremos:\n",
    "* x = [id_tokens, token_type, attention_mask]\n",
    "* y = [id_start_token, id_end_token]\n",
    "* dataset = tf.Dataset.from_tensor_slices(({id_tokens: tf.cast, token_type: tf.cast, attention_mask: tf.cast}, {id_start_token: tf.cast, id_end_token: tf.cast}))\n",
    "* squad_Objects = [Objetos de tipo SquadExample]\n",
    "* Errores = [Id del del DF que no ha sido seleccionado para entrenamiento/validación]\n",
    "\n",
    "Se puede encontrar más información sobre el formato tf.Dataset [aquí](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices). Uno de los motivos de que se generen errores al transformar a un objeto de tipo SquadExample, es porque el contexto y la pregunta suman más de 384 tokens, que es la secuencia máxima permitida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8729f16b-6ed6-4d16-aee0-f994aea86834",
   "metadata": {},
   "source": [
    "* Entrenamiento: Convertimos los datos de tipo DF a tf.Dataset y también creamos los SquadExample de los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65726409-85e1-41d5-9e15-3f28c5e82e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-14 23:27:57,657 tfm-app.log INFO: Transformado el conjunto de entrenamiento al formato SquadExample\n",
      "2021-10-14 23:28:03,531 tfm-app.log INFO: Se ha conseguido obtener los inputs y los targets para el conjunto de entrenamiento. Se han creado  85629 puntos\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, train_dataset, train_squad_objects, train_errors = pp.transformar_datos_squad(train_df, tokenizador, config_BERT, logger=logger, name_data=\"entrenamiento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9f2fa5-bb9e-4630-a5f1-b648505f785f",
   "metadata": {},
   "source": [
    "* Validación: Convertimos los datos de tipo DF a tf.Dataset y también creamos los SquadExample de los datos de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b16b21e-cc89-4d99-9aa6-3c5184d83e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-14 23:28:10,812 tfm-app.log INFO: Transformado el conjunto de validación al formato SquadExample\n",
      "2021-10-14 23:28:11,388 tfm-app.log INFO: Se ha conseguido obtener los inputs y los targets para el conjunto de validación. Se han creado  9649 puntos\n"
     ]
    }
   ],
   "source": [
    "x_eval, y_eval, eval_dataset, eval_squad_objects, eval_errors = pp.transformar_datos_squad(eval_df, tokenizador, config_BERT, logger=logger, name_data=\"validación\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb7ca2-74e8-43d8-a5f9-fadf45f113cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "<a class=\"anchor\" id=\"cap2\"></a>\n",
    "## Capítulo 2: Construcción del modelo\n",
    "\n",
    "Llegamos a la parte donde iremos construyendo lo necesario para el entrenamiento de nuestro modelo y también la validación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222a0884-c8d2-4282-bc55-da34fa000ff5",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"cap2.1\"></a>\n",
    "### Hiperparámetros\n",
    "\n",
    "Tenemos por tanto la configuración del modelo BERT y de cómo vamos a entrenar el modelo ajustado para el Question Answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccb4ec1d-e94b-453f-a4c2-17342465d531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_probs_dropout_prob': 0.1,\n",
       " 'hidden_act': 'gelu',\n",
       " 'hidden_dropout_prob': 0.1,\n",
       " 'hidden_size': 768,\n",
       " 'initializer_range': 0.02,\n",
       " 'intermediate_size': 3072,\n",
       " 'max_position_embeddings': 512,\n",
       " 'num_attention_heads': 12,\n",
       " 'num_hidden_layers': 12,\n",
       " 'type_vocab_size': 2,\n",
       " 'vocab_size': 31002,\n",
       " 'max_seq_len': 384,\n",
       " 'lr': 0.05,\n",
       " 'batch_size': 64,\n",
       " 'nb_epoch': 20}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cfab7e7-c85f-4085-b274-40173ca52121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 19:31:16,381 tfm-app.log INFO: Modelo entrenado con los siguientes hiperparámetros: {'attention_probs_dropout_prob': 0.1, 'hidden_act': 'gelu', 'hidden_dropout_prob': 0.1, 'hidden_size': 768, 'initializer_range': 0.02, 'intermediate_size': 3072, 'max_position_embeddings': 512, 'num_attention_heads': 12, 'num_hidden_layers': 12, 'type_vocab_size': 2, 'vocab_size': 31002, 'max_seq_len': 384, 'lr': 0.05, 'batch_size': 64, 'nb_epoch': 20}\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Modelo entrenado con los siguientes hiperparámetros: {config_BERT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833da2b-a3ef-4dfe-b183-8961041fb6dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"cap2.2\"></a>\n",
    "### Callbacks\n",
    "\n",
    "Dentro del entrenamiento, queremos generar untos de control para poder ir almacenando en cada epoch el mejor modelo, centrarnos en minimizar la función de coste lo más rápido posible, poder visualizar las métricas que nos están saliendo para ver si estamos mejorando o no en la pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b3bbf2d-56e1-4c1a-9e51-c5f944d78774",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = tu.generar_callbacks(x_eval, y_eval, eval_squad_objects, logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc612246-3a1a-421d-bbf6-d59bbe374080",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cap2.3\"></a>\n",
    "### Formato Keras\n",
    "\n",
    "Convertimos todo el tf.Dataset en un conjunto de batches, que viene configurado en config_BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cf796be-0720-4ea8-a3b7-3fb6b2d183c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_keras = pp.input_formato_keras(train_dataset, config_BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d25c93a-1b5d-4c4a-a70d-c28d7b7b3a35",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cap2.4\"></a>\n",
    "### Modelo\n",
    "\n",
    "Se inicializa el modelo con toda la construcción inicial. Por debajo lleva librerías de Transformers de HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c2e4f7e-9e5a-409a-b801-dd2c264dae00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing TFBertForQuestionAnswering: ['mlm___cls']\n",
      "- This IS expected if you are initializing TFBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFBertForQuestionAnswering were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['qa_outputs']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2021-10-17 14:14:52,587 tfm-app.log INFO: Se ha realizado la carga del modelo para QA a partir del modelo preentrenado dccuchile/bert-base-spanish-wwm-cased.\n",
      "2021-10-17 14:14:52,592 tfm-app.log INFO: Se ha congelado la primera capa del modelo: bert\n",
      "2021-10-17 14:14:52,605 tfm-app.log INFO: Se ha compilado el modelo con Adam(lr=0.05) como Optimizador y SparseCategoricalCrossentropy como función de pérdida.\n",
      "2021-10-17 14:14:52,606 tfm-app.log INFO: Model: \"tf_bert_for_question_answering\"\n",
      "2021-10-17 14:14:52,608 tfm-app.log INFO: _________________________________________________________________\n",
      "2021-10-17 14:14:52,608 tfm-app.log INFO: Layer (type)                 Output Shape              Param #   \n",
      "2021-10-17 14:14:52,610 tfm-app.log INFO: =================================================================\n",
      "2021-10-17 14:14:52,618 tfm-app.log INFO: bert (TFBertMainLayer)       multiple                  109850880 \n",
      "2021-10-17 14:14:52,620 tfm-app.log INFO: _________________________________________________________________\n",
      "2021-10-17 14:14:52,622 tfm-app.log INFO: qa_outputs (Dense)           multiple                  1538      \n",
      "2021-10-17 14:14:52,623 tfm-app.log INFO: =================================================================\n",
      "2021-10-17 14:14:52,634 tfm-app.log INFO: Total params: 109,852,418\n",
      "2021-10-17 14:14:52,636 tfm-app.log INFO: Trainable params: 1,538\n",
      "2021-10-17 14:14:52,637 tfm-app.log INFO: Non-trainable params: 109,850,880\n",
      "2021-10-17 14:14:52,638 tfm-app.log INFO: _________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo = tu.obtener_modelo(logger=logger, config=config_BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeb202c-c88f-4e84-bac4-dbcfe1f6813e",
   "metadata": {},
   "source": [
    "Se puede apreciar cómo se ha congelado la capa base, donde tenemos el modelo Bert. Y tendremos la salida en el formato de índices de tokens donde está el inicio y fin de repuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b44cbb0b-4776-4052-a601-a0a82d02d4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_question_answering\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109850880 \n",
      "_________________________________________________________________\n",
      "qa_outputs (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 109,852,418\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,850,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f315ff8a-fd61-401d-a5af-245563416958",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "<a class=\"anchor\" id=\"cap3\"></a>\n",
    "## Capítulo 3: Entrenamiento y validación\n",
    "\n",
    "Iniciaremos el método fit de entrenamiento del modelo, pero antes, iniciamos el tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67761c84-97ee-41f0-b862-306b8e4acedd",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"cap3.1\"></a>\n",
    "### Monitorización en Tensorboard\n",
    "\n",
    "Hemos generado un callback específico del tensorboard para poder ir mirando las métricas asociadas al entrenamiento. En este caso, la función de coste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "511fb0cb-e8c5-454f-8753-881490df512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el tensorboard\n",
    "%load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be8137b4-652b-4448-9030-49e4808be23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 1916), started 0:00:56 ago. (Use '!kill 1916' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c8fafd8fa2841b50\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c8fafd8fa2841b50\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir '.\\..\\\\data\\\\logs\\\\tensorboard\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05a2384-859b-4395-a09b-ff10b8b4ebc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"cap3.2\"></a>\n",
    "### Entrenamiento\n",
    "\n",
    "Le pasamos el modelo, el dataset en formato de batches, la configuración del modelo, los callbacks generados y el fichero de logs para poder ir controlando el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58fff213-7148-49a9-9273-c9419cb5953a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-14 23:30:23,287 tfm-app.log INFO: Se realizará el entrenamiento con 20 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   1/1338 [..............................] - ETA: 0s - loss: 11.8042 - output_1_loss: 5.9276 - output_2_loss: 5.8766WARNING:tensorflow:From d:\\python_entornos\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 7.9015 - output_1_loss: 3.9903 - output_2_loss: 3.9112\n",
      "Epoch 00001: loss improved from inf to 7.90154, saving model to ..\\data\\checkpoints\\model.01-7.90.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 01:44:29,703 tfm-app.log INFO: \n",
      "epoch=1, exact match score=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=1, exact match score=0.00\n",
      "1338/1338 [==============================] - 8030s 6s/step - loss: 7.9015 - output_1_loss: 3.9903 - output_2_loss: 3.9112\n",
      "Epoch 2/20\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 7.8848 - output_1_loss: 3.9877 - output_2_loss: 3.8971\n",
      "Epoch 00002: loss improved from 7.90154 to 7.88476, saving model to ..\\data\\checkpoints\\model.02-7.88.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 03:58:28,133 tfm-app.log INFO: \n",
      "epoch=2, exact match score=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=2, exact match score=0.00\n",
      "1338/1338 [==============================] - 8033s 6s/step - loss: 7.8848 - output_1_loss: 3.9877 - output_2_loss: 3.8971\n",
      "Epoch 3/20\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 7.8930 - output_1_loss: 3.9771 - output_2_loss: 3.9160\n",
      "Epoch 00003: loss did not improve from 7.88476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 06:12:16,195 tfm-app.log INFO: \n",
      "epoch=3, exact match score=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=3, exact match score=0.00\n",
      "1338/1338 [==============================] - 8022s 6s/step - loss: 7.8930 - output_1_loss: 3.9771 - output_2_loss: 3.9160\n",
      "Epoch 4/20\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 7.8792 - output_1_loss: 3.9715 - output_2_loss: 3.9076\n",
      "Epoch 00004: loss improved from 7.88476 to 7.87917, saving model to ..\\data\\checkpoints\\model.04-7.88.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 08:26:06,606 tfm-app.log INFO: \n",
      "epoch=4, exact match score=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=4, exact match score=0.00\n",
      "1338/1338 [==============================] - 8025s 6s/step - loss: 7.8792 - output_1_loss: 3.9715 - output_2_loss: 3.9076\n",
      "Epoch 5/20\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 7.8852 - output_1_loss: 3.9794 - output_2_loss: 3.9058\n",
      "Epoch 00005: loss did not improve from 7.87917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 10:39:57,931 tfm-app.log INFO: \n",
      "epoch=5, exact match score=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=5, exact match score=0.00\n",
      "1338/1338 [==============================] - 8026s 6s/step - loss: 7.8852 - output_1_loss: 3.9794 - output_2_loss: 3.9058\n",
      "Epoch 6/20\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 7.8759 - output_1_loss: 3.9697 - output_2_loss: 3.9062\n",
      "Epoch 00006: loss improved from 7.87917 to 7.87586, saving model to ..\\data\\checkpoints\\model.06-7.88.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 12:53:59,360 tfm-app.log INFO: \n",
      "epoch=6, exact match score=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=6, exact match score=0.00\n",
      "1338/1338 [==============================] - 8036s 6s/step - loss: 7.8759 - output_1_loss: 3.9697 - output_2_loss: 3.9062\n",
      "Epoch 7/20\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 7.8915 - output_1_loss: 3.9788 - output_2_loss: 3.9128\n",
      "Epoch 00007: loss did not improve from 7.87586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 15:08:04,875 tfm-app.log INFO: \n",
      "epoch=7, exact match score=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=7, exact match score=0.00\n",
      "1338/1338 [==============================] - 8040s 6s/step - loss: 7.8915 - output_1_loss: 3.9788 - output_2_loss: 3.9128\n",
      "Epoch 8/20\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 7.9044 - output_1_loss: 3.9816 - output_2_loss: 3.9228\n",
      "Epoch 00008: loss did not improve from 7.87586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 17:22:07,800 tfm-app.log INFO: \n",
      "epoch=8, exact match score=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=8, exact match score=0.00\n",
      "1338/1338 [==============================] - 8037s 6s/step - loss: 7.9044 - output_1_loss: 3.9816 - output_2_loss: 3.9228\n",
      "Epoch 9/20\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 7.8640 - output_1_loss: 3.9720 - output_2_loss: 3.8920\n",
      "Epoch 00009: loss improved from 7.87586 to 7.86398, saving model to ..\\data\\checkpoints\\model.09-7.86.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 19:36:12,966 tfm-app.log INFO: \n",
      "epoch=9, exact match score=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=9, exact match score=0.00\n",
      "1338/1338 [==============================] - 8040s 6s/step - loss: 7.8640 - output_1_loss: 3.9720 - output_2_loss: 3.8920\n",
      "Epoch 10/20\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 7.8849 - output_1_loss: 3.9742 - output_2_loss: 3.9107\n",
      "Epoch 00010: loss did not improve from 7.86398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 21:50:15,184 tfm-app.log INFO: \n",
      "epoch=10, exact match score=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=10, exact match score=0.00\n",
      "1338/1338 [==============================] - 8037s 6s/step - loss: 7.8849 - output_1_loss: 3.9742 - output_2_loss: 3.9107\n",
      "Epoch 11/20\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 7.8931 - output_1_loss: 3.9822 - output_2_loss: 3.9109\n",
      "Epoch 00011: loss did not improve from 7.86398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-16 00:04:26,239 tfm-app.log INFO: \n",
      "epoch=11, exact match score=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=11, exact match score=0.00\n",
      "1338/1338 [==============================] - 8045s 6s/step - loss: 7.8931 - output_1_loss: 3.9822 - output_2_loss: 3.9109\n",
      "Epoch 12/20\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 7.8745 - output_1_loss: 3.9726 - output_2_loss: 3.9019\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.005000000074505806.\n",
      "\n",
      "Epoch 00012: loss did not improve from 7.86398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-16 02:18:17,994 tfm-app.log INFO: \n",
      "epoch=12, exact match score=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=12, exact match score=0.00\n",
      "1338/1338 [==============================] - 8026s 6s/step - loss: 7.8745 - output_1_loss: 3.9726 - output_2_loss: 3.9019\n",
      "Epoch 13/20\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 7.0420 - output_1_loss: 3.5600 - output_2_loss: 3.4820\n",
      "Epoch 00013: loss improved from 7.86398 to 7.04197, saving model to ..\\data\\checkpoints\\model.13-7.04.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-16 04:32:13,791 tfm-app.log INFO: \n",
      "epoch=13, exact match score=0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=13, exact match score=0.01\n",
      "1338/1338 [==============================] - 8030s 6s/step - loss: 7.0420 - output_1_loss: 3.5600 - output_2_loss: 3.4820\n",
      "Epoch 14/20\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 7.0091 - output_1_loss: 3.5444 - output_2_loss: 3.4647\n",
      "Epoch 00014: loss improved from 7.04197 to 7.00909, saving model to ..\\data\\checkpoints\\model.14-7.01.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-16 06:46:02,752 tfm-app.log INFO: \n",
      "epoch=14, exact match score=0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=14, exact match score=0.01\n",
      "1338/1338 [==============================] - 8023s 6s/step - loss: 7.0091 - output_1_loss: 3.5444 - output_2_loss: 3.4647\n",
      "Epoch 15/20\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 7.0101 - output_1_loss: 3.5423 - output_2_loss: 3.4678\n",
      "Epoch 00015: loss did not improve from 7.00909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-16 08:59:52,589 tfm-app.log INFO: \n",
      "epoch=15, exact match score=0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=15, exact match score=0.01\n",
      "1338/1338 [==============================] - 8024s 6s/step - loss: 7.0101 - output_1_loss: 3.5423 - output_2_loss: 3.4678\n",
      "Epoch 16/20\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 7.0116 - output_1_loss: 3.5453 - output_2_loss: 3.4663\n",
      "Epoch 00016: loss did not improve from 7.00909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-16 11:13:43,037 tfm-app.log INFO: \n",
      "epoch=16, exact match score=0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=16, exact match score=0.01\n",
      "1338/1338 [==============================] - 8025s 6s/step - loss: 7.0116 - output_1_loss: 3.5453 - output_2_loss: 3.4663\n",
      "Epoch 17/20\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 7.0064 - output_1_loss: 3.5423 - output_2_loss: 3.4642\n",
      "Epoch 00017: loss improved from 7.00909 to 7.00644, saving model to ..\\data\\checkpoints\\model.17-7.01.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-16 13:27:36,401 tfm-app.log INFO: \n",
      "epoch=17, exact match score=0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=17, exact match score=0.01\n",
      "1338/1338 [==============================] - 8028s 6s/step - loss: 7.0064 - output_1_loss: 3.5423 - output_2_loss: 3.4642\n",
      "Epoch 18/20\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 7.0067 - output_1_loss: 3.5415 - output_2_loss: 3.4651\n",
      "Epoch 00018: loss did not improve from 7.00644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-16 15:41:33,783 tfm-app.log INFO: \n",
      "epoch=18, exact match score=0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=18, exact match score=0.01\n",
      "1338/1338 [==============================] - 8032s 6s/step - loss: 7.0067 - output_1_loss: 3.5415 - output_2_loss: 3.4651\n",
      "Epoch 19/20\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 7.0027 - output_1_loss: 3.5422 - output_2_loss: 3.4605\n",
      "Epoch 00019: loss improved from 7.00644 to 7.00272, saving model to ..\\data\\checkpoints\\model.19-7.00.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-16 17:55:25,923 tfm-app.log INFO: \n",
      "epoch=19, exact match score=0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=19, exact match score=0.01\n",
      "1338/1338 [==============================] - 8027s 6s/step - loss: 7.0027 - output_1_loss: 3.5422 - output_2_loss: 3.4605\n",
      "Epoch 20/20\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 7.0103 - output_1_loss: 3.5438 - output_2_loss: 3.4664\n",
      "Epoch 00020: loss did not improve from 7.00272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-16 20:09:19,993 tfm-app.log INFO: \n",
      "epoch=20, exact match score=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=20, exact match score=0.00\n",
      "1338/1338 [==============================] - 8028s 6s/step - loss: 7.0103 - output_1_loss: 3.5438 - output_2_loss: 3.4664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-16 20:09:20,172 tfm-app.log INFO: Entrenamiento finalizado!\n",
      "2021-10-16 20:09:20,248 tfm-app.log INFO: Guardando pesos...\n",
      "2021-10-16 20:09:21,484 tfm-app.log INFO: Se han guardado los pesos en: ..\\data\\models\\qa_model_squad_v2_esp\\qa_model_squad_v2_esp.h5\n",
      "2021-10-16 20:09:21,485 tfm-app.log INFO: Guardando Modelo Json...\n",
      "2021-10-16 20:09:21,487 tfm-app.log ERROR: \n"
     ]
    }
   ],
   "source": [
    "modeloHistory = tu.entrenar_modelo(modelo, train_dataset_keras, config_BERT, callbacks, logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3edfadc-d340-4b4c-a40b-f85132da711f",
   "metadata": {},
   "source": [
    "---\n",
    "<a class=\"anchor\" id=\"cap4\"></a>\n",
    "## Capítulo 4: Predicción\n",
    "\n",
    "Una vez tenemos nuestro modelo entrenado, procedemos a inferir nuestras respuestas a partir de una pregunta y un contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75b0007-2fd9-494a-a393-6daba0b6f289",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"cap4.1\"></a>\n",
    "### Carga de modelo\n",
    "\n",
    "Cargamos los modelos para realizar una inferencia sobre ellos. Tenemos nuestro modelo que hemos entrenado, pero también tenemos en local el [modelo distill Bert](https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es) que se utiliza en la aplicación, puesto que se ha entrenado en mejores capacidades computacionales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf8d3e9-b50c-4d0c-9abf-8daf60e6d13d",
   "metadata": {},
   "source": [
    "* Nuestro Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a84653e-2d0a-4684-ba6b-0b8999409b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing TFBertForQuestionAnswering: ['mlm___cls']\n",
      "- This IS expected if you are initializing TFBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFBertForQuestionAnswering were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['qa_outputs']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2021-11-09 17:01:51,545 tfm-app.log INFO: Se ha cargado el modelo qa_model_squad_v2_esp con éxito\n"
     ]
    }
   ],
   "source": [
    "modelo = tu.cargar_modelo(logger=logger, config=config_BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f5cfde3-45ea-43bc-a7ce-7e22bf6635ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_question_answering\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109850880 \n",
      "_________________________________________________________________\n",
      "qa_outputs (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 109,852,418\n",
      "Trainable params: 109,852,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1273acf1-6b9e-4c67-9356-260956724e76",
   "metadata": {},
   "source": [
    "* Modelo Remoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99492e75-c4d8-4fe4-8c2d-3a7cfae574f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing TFBertForQuestionAnswering: ['mlm___cls']\n",
      "- This IS expected if you are initializing TFBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFBertForQuestionAnswering were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['qa_outputs']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2021-11-09 17:03:42,280 tfm-app.log INFO: Se ha cargado el modelo remote_model con éxito\n"
     ]
    }
   ],
   "source": [
    "modelo_remoto = tu.cargar_modelo(model_name=\"remote_model\", logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d62ebc03-293c-45ab-abd2-e3122afb8497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_question_answering_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109850880 \n",
      "_________________________________________________________________\n",
      "qa_outputs (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 109,852,418\n",
      "Trainable params: 109,852,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo_remoto.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aed765-c88c-484c-9beb-a1b172fabcbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"cap4.2\"></a>\n",
    "### Dato a evaluar\n",
    "\n",
    "Elegimos de entre los datos de evaluación, un contexto y una pregunta y comparamos con la respuesta de verdad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "979e56c8-b0d8-428a-862e-f0e5ce419d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9905\n"
     ]
    }
   ],
   "source": [
    "eval_df.reset_index(drop=True, inplace=True)\n",
    "print(len(eval_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3addf045-08e3-44a4-972f-895f861356eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contexto:\n",
      "El servicio comenzó el 1 de septiembre de 1993 basado en la idea del entonces director ejecutivo, Sam Chisholm y Rupert Murdoch, de convertir la estrategia de negocio de la compañía a un concepto completamente basado en la fiebre. El nuevo paquete incluye cuatro canales que antes estaban disponibles de forma gratuita, transmitiendo en los satélites de Astra, así como la introducción de nuevos canales. El servicio continuó hasta el cierre del servicio analógico de BSkyB el 27 de septiembre de 2001, debido al lanzamiento y expansión de la plataforma Sky Digital. Algunos de los canales transmitieron ya sea en el cifrado claro o suave (por lo que se requería un decodificador VideoCrypt para decodificar, sin una tarjeta de suscripción) antes de su adición al paquete Sky Multichannels. A los dos meses del lanzamiento, BSkyB ganó 400,000 nuevos suscriptores, con la mayoría tomando al menos un canal premium también, lo que ayudó a BSkyB llegar a 3,5 millones de hogares a mediados de 1994. Michael Grade criticó las operaciones frente al Select Committee on National Heritage, principalmente por la falta de programación original en muchos de los nuevos canales. \n",
      "\n",
      "Pregunta:\n",
      "¿De quién serán los satélites los nuevos canales gratuitos? \n",
      "\n",
      "Respuesta:\n",
      "satélites de Astra\n"
     ]
    }
   ],
   "source": [
    "ejemplo_id = 772\n",
    "context = eval_df.loc[ejemplo_id, \"Context\"]\n",
    "print(\"Contexto:\")\n",
    "print(context, \"\\n\")\n",
    "\n",
    "question = eval_df.loc[ejemplo_id, \"Question\"]\n",
    "print(\"Pregunta:\")\n",
    "print(question, \"\\n\")\n",
    "\n",
    "respuesta = eval_df.loc[ejemplo_id, \"Text\"]\n",
    "print(\"Respuesta:\")\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b261dc79-137d-4575-a3b3-f9efa1a84891",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cap4.3\"></a>\n",
    "### Modelo entrenado\n",
    "\n",
    "Primero, predecimos con nuestro modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28023782-1ac0-47e5-8480-179c6341bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta_predicha = pu.predict(question, context, modelo=modelo, tokenizer=tokenizador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6e45b4c-48fb-4b33-ac0c-5bf74195b29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': 3,\n",
       " 'end': 96,\n",
       " 'answer': 'el 1 de septiembre de 1993 basado en la idea del entonces director ejecutivo, Sam Chisholm y Rupert Murdoch, de convertir la estrategia de negocio de la compañía a un concepto completamente basado en la fiebre. El nuevo paquete incluye cuatro canales que antes estaban disponibles de forma gratuita, transmitiendo en los satélites de Astra, así como la introducción de nuevos canales. El servicio continuó hasta el cierre del servicio analógico de BSkyB el 27 de septiembre de 2001, debido al lanzamiento y expansión de la plataforma Sky Digital. Algunos de los canales transmitieron'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respuesta_predicha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "304de59b-0dfa-4144-a138-695adbe1234a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>¿DE QUIÉN SERÁN LOS SATÉLITES LOS NUEVOS CANALES GRATUITOS?</p>\n",
       "<blockquote> El servicio comenzó <mark>el 1 de septiembre de 1993 basado en la idea del entonces director ejecutivo, Sam Chisholm y Rupert Murdoch, de convertir la estrategia de negocio de la compañía a un concepto completamente basado en la fiebre. El nuevo paquete incluye cuatro canales que antes estaban disponibles de forma gratuita, transmitiendo en los satélites de Astra, así como la introducción de nuevos canales. El servicio continuó hasta el cierre del servicio analógico de BSkyB el 27 de septiembre de 2001, debido al lanzamiento y expansión de la plataforma Sky Digital. Algunos de los canales transmitieron</mark> ya sea en el cifrado claro o suave (por lo que se requería un decodificador VideoCrypt para decodificar, sin una tarjeta de suscripción) antes de su adición al paquete Sky Multichannels. A los dos meses del lanzamiento, BSkyB ganó 400,000 nuevos suscriptores, con la mayoría tomando al menos un canal premium también, lo que ayudó a BSkyB llegar a 3,5 millones de hogares a mediados de 1994. Michael Grade criticó las operaciones frente al Select Committee on National Heritage, principalmente por la falta de programación original en muchos de los nuevos canales. </blockquote>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "marked_text = str(context.replace(respuesta_predicha['answer'], f\"<mark>{respuesta_predicha['answer']}</mark>\"))\n",
    "HTML(f\"<p>{question.upper()}</p>\\n\" + f\"\"\"<blockquote> {marked_text} </blockquote>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cfe2ef-5412-41a7-8c89-10cc12d4ffd1",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cap4.4\"></a>\n",
    "### Modelo Remoto\n",
    "\n",
    "Seguimos con el modelo en remoto, pero que lo tenemos descargado en local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0439f13c-ccb0-485e-b047-0347274bf4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta_predicha_remoto = pu.predict(question, context, modelo=modelo_remoto, tokenizer=tokenizador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66fcab66-4880-4cd2-816f-bba5fc79d52d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': 67, 'end': 68, 'answer': 'continuó hasta'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respuesta_predicha_remoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c36fd93-b30a-44b6-8f9e-22de3630c5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>¿DE QUIÉN SERÁN LOS SATÉLITES LOS NUEVOS CANALES GRATUITOS?</p>\n",
       "<blockquote> El servicio comenzó el 1 de septiembre de 1993 basado en la idea del entonces director ejecutivo, Sam Chisholm y Rupert Murdoch, de convertir la estrategia de negocio de la compañía a un concepto completamente basado en la fiebre. El nuevo paquete incluye cuatro canales que antes estaban disponibles de forma gratuita, transmitiendo en los satélites de Astra, así como la introducción de nuevos canales. El servicio <mark>continuó hasta</mark> el cierre del servicio analógico de BSkyB el 27 de septiembre de 2001, debido al lanzamiento y expansión de la plataforma Sky Digital. Algunos de los canales transmitieron ya sea en el cifrado claro o suave (por lo que se requería un decodificador VideoCrypt para decodificar, sin una tarjeta de suscripción) antes de su adición al paquete Sky Multichannels. A los dos meses del lanzamiento, BSkyB ganó 400,000 nuevos suscriptores, con la mayoría tomando al menos un canal premium también, lo que ayudó a BSkyB llegar a 3,5 millones de hogares a mediados de 1994. Michael Grade criticó las operaciones frente al Select Committee on National Heritage, principalmente por la falta de programación original en muchos de los nuevos canales. </blockquote>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "marked_text = str(context.replace(respuesta_predicha_remoto['answer'], f\"<mark>{respuesta_predicha_remoto['answer']}</mark>\"))\n",
    "HTML(f\"<p>{question.upper()}</p>\\n\" + f\"\"\"<blockquote> {marked_text} </blockquote>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab126600-2d08-4917-971b-8b2dd146a67c",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cap4.5\"></a>\n",
    "### Pipeline\n",
    "\n",
    "Aunque, por si hubiera algún error de formato al descargarlo en local, podemos inferir directamente haciendo peticiones HTTP al repositorio del [modelo de huggingFace](https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a29a64f-273a-4b93-adea-2cc0dec3b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta_predicha_pipeline = pu.predict(question, context, use_pipeline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0385eb2c-f3d9-495f-8c53-a9ad3fa07308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 1.104228203985258e-06,\n",
       " 'start': 341,\n",
       " 'end': 359,\n",
       " 'answer': 'satélites de Astra'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respuesta_predicha_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87b8a825-3ea0-4ac9-a2bd-bcbc186d53a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>¿DE QUIÉN SERÁN LOS SATÉLITES LOS NUEVOS CANALES GRATUITOS?</p>\n",
       "<blockquote> El servicio comenzó el 1 de septiembre de 1993 basado en la idea del entonces director ejecutivo, Sam Chisholm y Rupert Murdoch, de convertir la estrategia de negocio de la compañía a un concepto completamente basado en la fiebre. El nuevo paquete incluye cuatro canales que antes estaban disponibles de forma gratuita, transmitiendo en los <mark>satélites de Astra</mark>, así como la introducción de nuevos canales. El servicio continuó hasta el cierre del servicio analógico de BSkyB el 27 de septiembre de 2001, debido al lanzamiento y expansión de la plataforma Sky Digital. Algunos de los canales transmitieron ya sea en el cifrado claro o suave (por lo que se requería un decodificador VideoCrypt para decodificar, sin una tarjeta de suscripción) antes de su adición al paquete Sky Multichannels. A los dos meses del lanzamiento, BSkyB ganó 400,000 nuevos suscriptores, con la mayoría tomando al menos un canal premium también, lo que ayudó a BSkyB llegar a 3,5 millones de hogares a mediados de 1994. Michael Grade criticó las operaciones frente al Select Committee on National Heritage, principalmente por la falta de programación original en muchos de los nuevos canales. </blockquote>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "marked_text = str(context.replace(respuesta_predicha_pipeline['answer'], f\"<mark>{respuesta_predicha_pipeline['answer']}</mark>\"))\n",
    "HTML(f\"<p>{question.upper()}</p>\\n\" + f\"\"\"<blockquote> {marked_text} </blockquote>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3d3e2a-1af8-4030-bc09-d8c21e85e009",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
