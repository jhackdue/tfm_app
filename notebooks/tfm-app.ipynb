{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78740f79-8531-4a62-9f4f-5adef89bc748",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Trabajo de Fin de Máster: Applicación Web sobre un modelo de Question Answering en español\n",
    "\n",
    "    \n",
    "Descripción de los objetivos del proyecto.\n",
    "- Imagen de Bert\n",
    "- ¿Cómo aprenderá Bert?\n",
    "- ¿Cómo disponibilizaremos la app final?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a49645-baf1-476f-acad-c81ef296efef",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Capítulo 0: Configuración Inicial\n",
    "\n",
    "### Importación de librerias\n",
    "\n",
    "Descripción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1e894d3-5ef1-4858-a1b4-c5264f985531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "ABS_DIR = os.path.join(os.getcwd(), \"..\")\n",
    "sys.path.append(ABS_DIR)\n",
    "\n",
    "\n",
    "import utils.read_and_write as rw\n",
    "import utils.preprocesado as pp\n",
    "import train.train_utils as tu\n",
    "import predict.predict_utils as pu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e790999e-916c-4202-babf-1485458b6cae",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Configuración del proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386460b8-8ebe-470e-9da5-047575c44c10",
   "metadata": {},
   "source": [
    "Desde la siguiente URL: https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\n",
    "\n",
    "* Descargamos los ficheros de entrenamiento y evalución de SQuAD en español\n",
    "* Descargamos los ficheros de vocab y config con los que se entrenó BETO (Spanish BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "241422d1-9ed0-4e17-8221-d798752988eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-14 23:03:45,307 tfm-app.log INFO: El fichero log tfm-app.log ha sido creado\n",
      "2021-10-14 23:03:45,310 tfm-app.log INFO: El fichero train-v2.0-es.json existe en D:\\tfm_app\\src\\notebooks\\..\\data\\datasets\n",
      "2021-10-14 23:03:45,311 tfm-app.log INFO: El fichero dev-v2.0-es.json existe en D:\\tfm_app\\src\\notebooks\\..\\data\\datasets\n",
      "2021-10-14 23:03:45,312 tfm-app.log INFO: El fichero vocab.txt existe en D:\\tfm_app\\src\\notebooks\\..\\data\\models\n",
      "2021-10-14 23:03:45,314 tfm-app.log INFO: El fichero config.json existe en D:\\tfm_app\\src\\notebooks\\..\\data\\models\n"
     ]
    }
   ],
   "source": [
    "CONFIG_DIR = os.path.join(ABS_DIR, \"config\\\\\")\n",
    "\n",
    "DATA_DIR = os.path.join(ABS_DIR, \"data\\\\\")\n",
    "LOG_DIR = os.path.join(DATA_DIR, \"logs\\\\\")\n",
    "MODELS_DIR = os.path.join(DATA_DIR, \"models\\\\\")\n",
    "DATASETS_DIR = os.path.join(DATA_DIR, \"datasets\\\\\")\n",
    "CHECKPOINTS_CALLBACK_DIR = os.path.join(DATA_DIR, \"checkpoints\\\\\")\n",
    "CACHE_DIR = os.path.join(DATA_DIR, \"cache\\\\\")\n",
    "\n",
    "logger = rw.crear_logger(\"tfm-app.log\")\n",
    "\n",
    "train_path = rw.comprobar_fichero_existe(os.path.join(DATASETS_DIR, \"train-v2.0-es.json\"), logger)\n",
    "eval_path = rw.comprobar_fichero_existe(os.path.join(DATASETS_DIR, \"dev-v2.0-es.json\"), logger)\n",
    "\n",
    "vocab_BERT_path = rw.comprobar_fichero_existe(os.path.join(MODELS_DIR, \"vocab.txt\"), logger)\n",
    "config_BERT_path = rw.comprobar_fichero_existe(os.path.join(MODELS_DIR, \"config.json\"), logger)\n",
    "\n",
    "config_file = rw.cargar_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3f3e5b-eee6-4f8b-9e28-91085be66a7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualización de datos\n",
    "\n",
    "Explicación de cómo son los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a5a104c-b2a3-4a0e-b0c9-395b78c6c90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86818, 6)\n",
      "(9905, 6)\n"
     ]
    }
   ],
   "source": [
    "train_df = rw.json_to_dataframe(train_path)\n",
    "print(train_df.shape)\n",
    "eval_df = rw.json_to_dataframe(eval_path)\n",
    "print(eval_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7877eed1-42f1-46c8-93bf-d6e5c40168db",
   "metadata": {},
   "source": [
    "* ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf9734de-84c1-41b4-bd14-52b5fb997560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título:\n",
      " Budismo\n",
      "------------------------------------------------------------------------------------------\n",
      "Párrafo:\n",
      " La segunda verdad es que el origen de la dukkha puede ser conocido. En el contexto de las cuatro verdades nobles, el origen de dukkha se explica comúnmente como deseo (Pali: Tanha) condicionado por la ignorancia (Pali: Avijja). En un nivel más profundo, la causa raíz del dukkha se identifica como ignorancia (Pali: Avijja) de la verdadera naturaleza de las cosas. La tercera verdad noble es que el cese completo de la dukkha es posible, y la cuarta verdad noble identifica un camino a este cese. [Nota 7]\n",
      "------------------------------------------------------------------------------------------\n",
      "Pregunta:\n",
      " El origen del dukkha se explica como deseo condicionado por qué?\n",
      "------------------------------------------------------------------------------------------\n",
      "Posicion de respuesta:\n",
      " 201\n",
      "------------------------------------------------------------------------------------------\n",
      "Respuesta:\n",
      " ignorancia\n"
     ]
    }
   ],
   "source": [
    "id_row = 5000\n",
    "print(f\"Título:\\n {train_df.iloc[id_row, 1]}\")\n",
    "print(\"---\"*30)\n",
    "print(f\"Párrafo:\\n {train_df.iloc[id_row, 2]}\")\n",
    "print(\"---\"*30)\n",
    "print(f\"Pregunta:\\n {train_df.iloc[id_row, 3]}\")\n",
    "print(\"---\"*30)\n",
    "print(f\"Posicion de respuesta:\\n {train_df.iloc[id_row, 4]}\")\n",
    "print(\"---\"*30)\n",
    "print(f\"Respuesta:\\n {train_df.iloc[id_row, 5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d352c444-4122-4fed-8f37-ef3b35b9d7ee",
   "metadata": {},
   "source": [
    "* VALIDACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1807e35-592e-4e49-9029-dcd398efab5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título:\n",
      " Escuela privada\n",
      "------------------------------------------------------------------------------------------\n",
      "Párrafo:\n",
      " Las escuelas religiosas afiliadas y denominacionales forman una subcategoría de escuelas privadas. Algunas de estas escuelas enseñan educación religiosa, junto con los sujetos académicos habituales para impresionar las creencias y tradiciones de su fe particular en los estudiantes que asisten. Otros usan la denominación como una etiqueta más general para describir lo que los fundadores basaron en su creencia, manteniendo una fina distinción entre académicos y religión. Incluyen escuelas parroquiales, un término que a menudo se utiliza para denotar escuelas católicas romanas. Otros grupos religiosos representados en el sector de la educación privada K-12 incluyen protestantes, judíos, musulmanes y cristianos ortodoxos.\n",
      "------------------------------------------------------------------------------------------\n",
      "Pregunta:\n",
      " Junto con musulmanes, judíos y cristianos protestantes, ¿qué grupo religioso opera en particular escuelas privadas?\n",
      "------------------------------------------------------------------------------------------\n",
      "Posicion de respuesta:\n",
      " 563\n",
      "------------------------------------------------------------------------------------------\n",
      "Respuesta:\n",
      " católica\n"
     ]
    }
   ],
   "source": [
    "id_row = 5000\n",
    "print(f\"Título:\\n {eval_df.iloc[id_row, 1]}\")\n",
    "print(\"---\"*30)\n",
    "print(f\"Párrafo:\\n {eval_df.iloc[id_row, 2]}\")\n",
    "print(\"---\"*30)\n",
    "print(f\"Pregunta:\\n {eval_df.iloc[id_row, 3]}\")\n",
    "print(\"---\"*30)\n",
    "print(f\"Posicion de respuesta:\\n {eval_df.iloc[id_row, 4]}\")\n",
    "print(\"---\"*30)\n",
    "print(f\"Respuesta:\\n {eval_df.iloc[id_row, 5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc633059-e92b-442a-9edb-fab1cfc65475",
   "metadata": {},
   "source": [
    "---\n",
    "## Capítulo 1: Preprocesado de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24a0e7-4512-4877-92b6-337523accfdf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Configurando el tokenizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1693d3cf-9530-4a00-a758-637f57af595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizador = pp.obtener_tokenizador(vocab=vocab_BERT_path, lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "438d5d85-95ad-41c1-a840-e9e72d8298e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids: [4, 2098, 1058, 1108, 3889, 1110, 1292, 2078, 1062, 3, 5]\n",
      "tokens: ['[CLS]', 'Esto', 'es', 'una', 'prueba', 'para', 'ver', 'cómo', 'se', '[UNK]', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizador.encode(\"Esto es una prueba para ver cómo se tokeniza\")\n",
    "print(f'ids: {tokens.ids}')\n",
    "print(f'tokens: {tokens.tokens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8936e775-7c28-4e07-baa8-de861014814c",
   "metadata": {},
   "source": [
    "### Modificando la configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b17e121-5de7-47e1-8e3c-4bdd51ec9dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(config_BERT_path, 'r') as json_file:\n",
    "    config_BERT = json.load(json_file)\n",
    "config_BERT.update(config_file[\"train\"][\"preprocess\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b9eec0-e814-4cb3-9acb-ae8296736262",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8729f16b-6ed6-4d16-aee0-f994aea86834",
   "metadata": {},
   "source": [
    "* Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65726409-85e1-41d5-9e15-3f28c5e82e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-14 23:05:02,925 tfm-app.log INFO: Transformado el conjunto de entrenamiento al formato SquadExample\n",
      "2021-10-14 23:05:08,854 tfm-app.log INFO: Se ha conseguido obtener los inputs y los targets para el conjunto de entrenamiento. Se han creado  85629 puntos\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, train_dataset, train_squad_objects, train_errors = pp.transformar_datos_squad(train_df, tokenizador, config_BERT, logger=logger, name_data=\"entrenamiento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9f2fa5-bb9e-4630-a5f1-b648505f785f",
   "metadata": {},
   "source": [
    "* Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b16b21e-cc89-4d99-9aa6-3c5184d83e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-14 23:05:16,230 tfm-app.log INFO: Transformado el conjunto de validación al formato SquadExample\n",
      "2021-10-14 23:05:16,905 tfm-app.log INFO: Se ha conseguido obtener los inputs y los targets para el conjunto de validación. Se han creado  9649 puntos\n"
     ]
    }
   ],
   "source": [
    "x_eval, y_eval, eval_dataset, eval_squad_objects, eval_errors = pp.transformar_datos_squad(eval_df, tokenizador, config_BERT, logger=logger, name_data=\"validación\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb7ca2-74e8-43d8-a5f9-fadf45f113cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Capítulo 2: Construcción del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222a0884-c8d2-4282-bc55-da34fa000ff5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccb4ec1d-e94b-453f-a4c2-17342465d531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_probs_dropout_prob': 0.1,\n",
       " 'hidden_act': 'gelu',\n",
       " 'hidden_dropout_prob': 0.1,\n",
       " 'hidden_size': 768,\n",
       " 'initializer_range': 0.02,\n",
       " 'intermediate_size': 3072,\n",
       " 'max_position_embeddings': 512,\n",
       " 'num_attention_heads': 12,\n",
       " 'num_hidden_layers': 12,\n",
       " 'type_vocab_size': 2,\n",
       " 'vocab_size': 31002,\n",
       " 'max_seq_len': 384,\n",
       " 'lr': 0.05,\n",
       " 'batch_size': 64,\n",
       " 'nb_epoch': 20}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833da2b-a3ef-4dfe-b183-8961041fb6dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b3bbf2d-56e1-4c1a-9e51-c5f944d78774",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = tu.generar_callbacks(x_eval, y_eval, eval_squad_objects, logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc612246-3a1a-421d-bbf6-d59bbe374080",
   "metadata": {},
   "source": [
    "### Formato Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cf796be-0720-4ea8-a3b7-3fb6b2d183c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_keras = pp.input_formato_keras(train_dataset, config_BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d25c93a-1b5d-4c4a-a70d-c28d7b7b3a35",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c2e4f7e-9e5a-409a-b801-dd2c264dae00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing TFBertForQuestionAnswering: ['mlm___cls']\n",
      "- This IS expected if you are initializing TFBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFBertForQuestionAnswering were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['qa_outputs']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2021-10-14 23:05:19,370 tfm-app.log INFO: Se ha realizado la carga del modelo para QA a partir del modelo preentrenado dccuchile/bert-base-spanish-wwm-cased.\n",
      "2021-10-14 23:05:19,375 tfm-app.log INFO: Se ha congelado la primera capa del modelo: bert\n",
      "2021-10-14 23:05:19,385 tfm-app.log INFO: Se ha compilado el modelo con Adam(lr=0.05) como Optimizador y SparseCategoricalCrossentropy como función de pérdida.\n",
      "2021-10-14 23:05:19,386 tfm-app.log INFO: Model: \"tf_bert_for_question_answering\"\n",
      "2021-10-14 23:05:19,387 tfm-app.log INFO: _________________________________________________________________\n",
      "2021-10-14 23:05:19,388 tfm-app.log INFO: Layer (type)                 Output Shape              Param #   \n",
      "2021-10-14 23:05:19,388 tfm-app.log INFO: =================================================================\n",
      "2021-10-14 23:05:19,395 tfm-app.log INFO: bert (TFBertMainLayer)       multiple                  109850880 \n",
      "2021-10-14 23:05:19,396 tfm-app.log INFO: _________________________________________________________________\n",
      "2021-10-14 23:05:19,397 tfm-app.log INFO: qa_outputs (Dense)           multiple                  1538      \n",
      "2021-10-14 23:05:19,398 tfm-app.log INFO: =================================================================\n",
      "2021-10-14 23:05:19,407 tfm-app.log INFO: Total params: 109,852,418\n",
      "2021-10-14 23:05:19,408 tfm-app.log INFO: Trainable params: 1,538\n",
      "2021-10-14 23:05:19,409 tfm-app.log INFO: Non-trainable params: 109,850,880\n",
      "2021-10-14 23:05:19,409 tfm-app.log INFO: _________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo = tu.obtener_modelo(logger=logger, config=config_BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b44cbb0b-4776-4052-a601-a0a82d02d4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_question_answering\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109850880 \n",
      "_________________________________________________________________\n",
      "qa_outputs (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 109,852,418\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,850,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f315ff8a-fd61-401d-a5af-245563416958",
   "metadata": {},
   "source": [
    "## Capítulo 3: Entrenamiento y validación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67761c84-97ee-41f0-b862-306b8e4acedd",
   "metadata": {},
   "source": [
    "### Monitorización en Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "511fb0cb-e8c5-454f-8753-881490df512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el tensorboard\n",
    "%load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4b0d7ca-133a-4648-b191-69935de4414d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 2028."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir '..\\\\data\\\\logs\\\\tensorboard\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05a2384-859b-4395-a09b-ff10b8b4ebc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58fff213-7148-49a9-9273-c9419cb5953a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-14 23:06:33,247 tfm-app.log INFO: Se realizará el entrenamiento con 20 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   1/1338 [..............................] - ETA: 0s - loss: 11.8802 - output_1_loss: 5.9133 - output_2_loss: 5.9669WARNING:tensorflow:From d:\\python_entornos\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  51/1338 [>.............................] - ETA: 1:55:54 - loss: 8.0869 - output_1_loss: 4.0228 - output_2_loss: 4.0641"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12140/3675363013.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodeloHistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentrenar_modelo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset_keras\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig_BERT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\tfm_app\\src\\notebooks\\..\\train\\train_utils.py\u001b[0m in \u001b[0;36mentrenar_modelo\u001b[1;34m(modelo, dataset, config, callbacks, model_name, logger)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         \u001b[0mmod_hist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python_entornos\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python_entornos\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python_entornos\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python_entornos\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python_entornos\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python_entornos\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32md:\\python_entornos\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32md:\\python_entornos\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python_entornos\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modeloHistory = tu.entrenar_modelo(modelo, train_dataset_keras, config_BERT, callbacks, logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3edfadc-d340-4b4c-a40b-f85132da711f",
   "metadata": {},
   "source": [
    "## Capítulo 4: Predicción sobre el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75b0007-2fd9-494a-a393-6daba0b6f289",
   "metadata": {},
   "source": [
    "### Carga del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84653e-2d0a-4684-ba6b-0b8999409b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = rw.cargar_modelo(logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5cfde3-45ea-43bc-a7ce-7e22bf6635ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aed765-c88c-484c-9beb-a1b172fabcbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3addf045-08e3-44a4-972f-895f861356eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplo_id = 0\n",
    "context = eval_df.loc[0, \"Context\"]\n",
    "print(\"Contexto:\")\n",
    "print(context, \"\\n\")\n",
    "\n",
    "question = eval_df.loc[0, \"Question\"]\n",
    "print(\"Pregunta:\")\n",
    "print(question, \"\\n\")\n",
    "\n",
    "respuesta = eval_df.loc[0, \"Text\"]\n",
    "print(\"Respuesta:\")\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f9f1b161-ea51-41b5-b490-c7a537a02710",
   "metadata": {},
   "source": [
    "respuesta_predicha = pu.predict(question, context, modelo=modelo, tokenizer=tokenizador)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6341cb2b-f0da-4eb6-890a-bb6ce3dc682c",
   "metadata": {},
   "source": [
    "respuesta_predicha_pipeline = pu.predict(question, context, \n",
    "                                         modelo='mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es', \n",
    "                                         tokenizer=('mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es', {\"use_fast\": False}),\n",
    "                                         use_pipeline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7cf3fa-17c4-46c5-8f1b-e2794d4ced07",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(MODELS_DIR, \"tfm_bert_finetuned_squadV2esp\\\\v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42dbbce-a77c-4d39-82d9-3b731e3e3493",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.load_weights(os.path.join(MODELS_DIR, \"tfm_bert_finetuned_squadV2esp\\\\v1\\\\saved_model.pb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e893c7-1d9f-4880-9168-634597595bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "for count, inputs in enumerate(eval_dataset.batch(16)):\n",
    "    x, _ = inputs  \n",
    "    start_logits, end_logits = modelo(x, training=False)\n",
    "    output_dict = dict(\n",
    "        start_logits=start_logits,\n",
    "        end_logits=end_logits)\n",
    "    for result in get_raw_results(output_dict):\n",
    "        all_results.append(result)\n",
    "    if count % 100 == 0:\n",
    "        print(\"{}/{}\".format(count, 2709))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d039f53-36be-4c79-9ea6-82dddceb88f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_start, pred_end = modelo.predict(eval_dataset.batch(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2114606-e59e-4823-a86f-657cb2abce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"Esto es una texto de prueba.\\n Vamos a ver si funciona\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055fb0e8-62b3-4a4d-8950-4966ff27423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e422a7a-de0b-42fc-a710-d5c529a643db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pu.whitespace_split(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4b579f-5291-46c7-bcfa-a7587e4e04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tokens = [\"E\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476aa820-36bd-48de-933b-4877a4741294",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tokens[-1] += \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98754d9-a504-4d5f-af8f-734e139dd69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5614ceff-267c-4c78-90c3-a3530b97ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in texto:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23a706e-9f09-4c45-b2df-a9a7d2aa0f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304de59b-0dfa-4144-a138-695adbe1234a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e7888-29a1-41c8-87ab-c54aa395d29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87310646-398f-4eb6-a803-1efcbb0c59b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
